{
    "contents" : "---\ntitle: \"Course Project\"\nauthor: \"ahs\"\ndate: \"December 14, 2014\"\noutput: html_document\n---\nProject Goal\nThe goal of this project is to determine how well people perform a particular exercise. \n\n```{r echo=FALSE, warning=FALSE, error=FALSE}\n# Load libraries\nlibrary(caret)\nlibrary(rattle)\nlibrary(dplyr)\nlibrary(randomForest)\n\n# Load the data\ntrain_data <- read.csv('pml-training.csv')\n\n\n```\n\n1. Load the training data. \n2. Do some exploration. \n    + PCA to figure out what variables to get rid of. \n    + \n3. Decide on a model\n  + Regression/linear model\n  + Classification tree\n  + Random forest\n  \n# Exploration\nHow to deal with NA values\n\n\n```{r echo=FALSE, warning=FALSE, error=FALSE}\n# \n# # Figure out if any column is all NAs\n# sapply(train_data, function(x)all(is.na(x)))\n# \n# # It's not, so figure out how many columns are MOSTLY NAs. \n# sapply(train_data, \n#        function(x)NROW(na.omit(x))/NROW(x))\n# \n# # Looking at the results, we see that all columns have either all measures \n# #   or the same number of non-measures. Let's get rid of the columns \n# #   that have 2% of values. \n# sapply(train_data, \n#        function(x)NROW(na.omit(x)))\n\n# Turn it into a logical expression so we can use it for filtering\nkeep_cols <- sapply(train_data, \n       function(x)NROW(na.omit(x))!=406)\n\ntrain_data <- train_data[keep_cols]\n\n# We still have a bunch of columns with empty values, because \n# it sees \"\" as a factor level. I think these also have \"#DIV/0\" as a factor \n# level. Let's see if we can figure out which columns can be removed based\n# on this. \n\n# We have a couple columns we need to fix. \ntrain_data$cvtd_timestamp <- as.character(train_data$cvtd_timestamp)\n# I'm not quite sure if this is how i want to handle this, but it's what it is for now. \ntrain_data$new_window <- as.character(train_data$new_window)\n\nkeep_cols_2 <- sapply(train_data, function(x)!any(levels(x)=='#DIV/0!'))\ntrain_data <- train_data[keep_cols_2]\n      \n\n\n```\n\nNow we have `r ncol(train_data)` columns of data. \n\n```{r echo=FALSE, warning=FALSE, error=FALSE}\ntrain_data <- train_data[2:60]\n\n# modFit <- train(classe ~ .,method=\"rpart\", data=train_data[1:2000,])\n# print(modFit$finalModel)\n# plot(modFit$finalModel, uniform=TRUE, main=\"Classification Tree\")\n# text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)\n# fancyRpartPlot(modFit$finalModel)\n\n```\n\n\n\n```{r  echo=FALSE, warning=FALSE, error=FALSE}\n\ntrain_data$win_ind <- ave(train_data$new_window==\"yes\", FUN = function(x) {\n            cumsum(x) })\n\n# foo <- data.frame(diff(train_data$raw_timestamp_part_2))\n# foo<- rbind(0,foo)\n# colnames(foo) <- c(\"t2_delta\")\n# foo[foo$some_diff < 0,] <- 0\n\n# Another way to do this, but it creates a group, which I may or may not want. \ntrain_data <- group_by(train_data, num_window) %>% mutate(t2_delta = c(0,diff(raw_timestamp_part_2)))\n\n\n\n\n```\n\n\n```{r echo=FALSE, warning=FALSE, error=FALSE}\n\n# Okay, building a ctree again. \ntrain_data <- train_data[6:61]\n\n#modFit <- train(classe ~ .,method=\"rpart\", data=train_data[,-55]) # excluding \"win_ind\"\n#save(modFit, file=\"myClassTree.RData\")\n\n# Instead of training again, just load the saved one from file. \nload(\"myClassTree.RData\")\n\nprint(modFit$finalModel)\nplot(modFit$finalModel, uniform=TRUE, main=\"Classification Tree\")\ntext(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)\nfancyRpartPlot(modFit$finalModel)\n\n\n```\n\n\nEnough of this, let's generate a random forest. \n\n```{r echo=FALSE, warning=FALSE, error=FALSE}\n\nin_small_train <- createDataPartition(y=train_data$classe,p=0.2, list=FALSE)\nsmall_td <- train_data[in_small_train,]\n\n#modFit_rf <- train(classe~.,data=small_td,method=\"rf\",prox=TRUE)\n#save(modFit_rf, file=\"myRandomForest.RData\")\n\nload(file=\"myRandomForest.RData\")\n\n\n```\n\nEvaluating the result on the data we trained with: \n\n```{r echo=FALSE, warning=FALSE, error=FALSE}\ngetTree(modFit_rf$finalModel,k=2)\npred_train <- predict(modFit_rf, small_td)\nsmall_td$predRight <- pred_train==small_td$classe\ntable(pred_train, small_td$classe)\n\n```\n\n```{r echo=FALSE, warning=FALSE, error=FALSE}\npred_train2 <- predict(modFit_rf, train_data)\ntrain_data$predRight <- pred_train2==train_data$classe\ntable(pred_train2, train_data$classe)\n\n\n```\n\n\n```{r echo=FALSE, warning=FALSE, error=FALSE}\n\nclean_test_data <- function(data){\n  \n  data <- data[keep_cols]\n  data <- data[keep_cols_2]\n  \n  # Get rid of X column\n  data <- data[2:60]\n  \n  \n  # Add the time diff column (t2_delta)\n  data <- group_by(data, num_window) %>% mutate(t2_delta = \n                                                  c(0,diff(raw_timestamp_part_2)))\n  \n   data$win_ind <- ave(data$new_window==\"yes\", FUN = function(x) {\n            cumsum(x) })\n  \n  # Get rid of other cols\n  data <- data[6:61]\n  \n \n  # Remove win_ind col\n\n}\n\n```\n\n# Testing\n\nClearly, something is wrong with my model because I predict that everything is A. \n\n```{r echo=FALSE, warning=FALSE, error=FALSE}\ntesting<- read.csv('pml-testing.csv')\n\n# Repeat the transforms, which are captured in a function. \n\nclean_test <- clean_test_data(testing)\n\npred_test <- predict(modFit_rf, clean_test)\npred_test\n\n```\n\n\n",
    "created" : 1418614283158.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1672664553",
    "id" : "66D99776",
    "lastKnownWriteTime" : 1419206247,
    "path" : "~/Documents/data/coursera/pml/project.Rmd",
    "project_path" : "project.Rmd",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_markdown"
}